{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RGC1cj6a3vl",
        "outputId": "273433bd-017f-48d8-be4f-02dfc5fa2709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (24.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2023.12.25)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.2.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (4.66.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras keras_nlp tensorflow tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras, keras_nlp"
      ],
      "metadata": {
        "id": "FXUaoWugbDpt"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_text = \"Bengaluru is the garden city of India\""
      ],
      "metadata": {
        "id": "ymn94PKAmst9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BartTokenizer.from_preset(\"bart_base_en\")"
      ],
      "metadata": {
        "id": "FllbVhC3mwHq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFME8r7pm2cq",
        "outputId": "a801cad5-2eba-434c-e66d-534b3b504209"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([ 387, 3314,  337, 5515,   16,    5, 5671,  343,    9,  666],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BartTokenizer.from_preset(\"bart_large_en\")"
      ],
      "metadata": {
        "id": "YQk7TIaem4V0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa1svi3-m_xO",
        "outputId": "fb95341d-eea2-434b-8fcc-c8d4bc82d543"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([ 387, 3314,  337, 5515,   16,    5, 5671,  343,    9,  666],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BertTokenizer.from_preset(\"bert_base_en\")"
      ],
      "metadata": {
        "id": "zD97VUnjnBU3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPoB1NtenMwE",
        "outputId": "8840c733-637d-4377-9cb4-d56def6fc0eb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([ 7756, 12328,  1110,  1103,  4605,  1331,  1104,  1726],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BloomTokenizer.from_preset(\"bloom_560m_multi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Za-Ms0SnOPL",
        "outputId": "5ed1bb05-7f18-472d-8ff0-1b3299dad26d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_560m_multi/3/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 215kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_560m_multi/3/download/tokenizer.json...\n",
            "100%|██████████| 453/453 [00:00<00:00, 637kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_560m_multi/3/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 11.9M/11.9M [00:00<00:00, 21.7MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_560m_multi/3/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 3.98M/3.98M [00:00<00:00, 9.29MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6JauUtln3ui",
        "outputId": "53c7b21c-e292-4e58-974f-664340892cb7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([209443,   5046,    632,    368,  74872,  13014,    461,  11759],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BloomTokenizer.from_preset(\"bloom_1.1b_multi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxvFNQRRn_qe",
        "outputId": "70ef19c6-13ee-473c-f887-02e1fd4bfff7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_1.1b_multi/1/download/metadata.json...\n",
            "100%|██████████| 142/142 [00:00<00:00, 213kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_1.1b_multi/1/download/tokenizer.json...\n",
            "100%|██████████| 453/453 [00:00<00:00, 610kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_1.1b_multi/1/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 11.9M/11.9M [00:00<00:00, 18.8MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloom_1.1b_multi/1/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 3.98M/3.98M [00:00<00:00, 9.31MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrBTC6r2oNTm",
        "outputId": "2c8ad9c3-6001-4a12-eea2-923421085b8c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([209443,   5046,    632,    368,  74872,  13014,    461,  11759],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BloomTokenizer.from_preset(\"bloomz_560m_multi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOFXP3CNoQvE",
        "outputId": "9bb06f50-1f35-4245-aa4d-05874609c6bc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloomz_560m_multi/1/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 198kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloomz_560m_multi/1/download/tokenizer.json...\n",
            "100%|██████████| 453/453 [00:00<00:00, 689kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloomz_560m_multi/1/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 11.9M/11.9M [00:00<00:00, 21.4MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bloom/keras/bloomz_560m_multi/1/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 3.98M/3.98M [00:00<00:00, 9.29MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CA2Fye5otmT",
        "outputId": "7e7977c1-05f0-4875-f7cd-7d4710bd3935"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([209443,   5046,    632,    368,  74872,  13014,    461,  11759],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.DebertaV3Tokenizer.from_preset(\"deberta_v3_extra_small_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2y87CxqoxQT",
        "outputId": "5516328d-8586-40fc-92a7-d5878934de2e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_extra_small_en/2/download/metadata.json...\n",
            "100%|██████████| 140/140 [00:00<00:00, 164kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_extra_small_en/2/download/tokenizer.json...\n",
            "100%|██████████| 424/424 [00:00<00:00, 397kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_extra_small_en/2/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 2.35M/2.35M [00:00<00:00, 6.11MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eUMUsyVo8ED",
        "outputId": "efca8d26-812b-4085-8a50-785b4491bc68"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([27263,   269,   262,  2058,   707,   265,  1280], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.DebertaV3Tokenizer.from_preset(\"deberta_v3_base_multi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t75Jkfb3o-bc",
        "outputId": "c72437fe-2703-4a6b-f01e-192e12027f08"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_base_multi/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 218kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_base_multi/2/download/tokenizer.json...\n",
            "100%|██████████| 424/424 [00:00<00:00, 645kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/deberta_v3/keras/deberta_v3_base_multi/2/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 4.11M/4.11M [00:00<00:00, 9.57MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEw_Y0WBpHHa",
        "outputId": "124022a4-48ca-446b-9c1f-f7502842006a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([   365, 140360,    340,    288,  23839,   9417,    305,   4784],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.DistilBertTokenizer.from_preset(\"distil_bert_base_en_uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIUk4e18pJ9f",
        "outputId": "d7b82147-7a16-4025-f7db-a3f92349be4e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/2/download/metadata.json...\n",
            "100%|██████████| 140/140 [00:00<00:00, 200kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/2/download/tokenizer.json...\n",
            "100%|██████████| 580/580 [00:00<00:00, 822kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/2/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 226k/226k [00:00<00:00, 1.19MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcXFF2oJpTcj",
        "outputId": "0ed3c35e-d946-4ed6-b186-5f38452c96fc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([ 8191, 14129,  2003,  1996,  3871,  2103,  1997,  2634],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.DistilBertTokenizer.from_preset(\"distil_bert_base_multi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBPNLNATpV-Y",
        "outputId": "b87c102e-6d7b-45e0-c105-40af52479e6a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_multi/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 181kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_multi/2/download/tokenizer.json...\n",
            "100%|██████████| 581/581 [00:00<00:00, 749kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_multi/2/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 972k/972k [00:00<00:00, 3.01MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"ಬೆಂಗಳೂರು ಸುಂದರವಾಗಿದೆ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Or7VmRpfeB",
        "outputId": "f7e91416-a5f8-422a-c023-39acc5dd6e01"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([ 1284, 13833, 80382, 31903, 54686,  1294, 14284, 38114, 99977,\n",
              "       27569], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.ElectraTokenizer.from_preset(\"electra_small_generator_uncased_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VzNULL5pmMv",
        "outputId": "6827ceaf-52cd-49bd-cb24-b0ef98bcc0c8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_small_generator_uncased_en/1/download/metadata.json...\n",
            "100%|██████████| 140/140 [00:00<00:00, 206kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_small_generator_uncased_en/1/download/tokenizer.json...\n",
            "100%|██████████| 559/559 [00:00<00:00, 721kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_small_generator_uncased_en/1/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 226k/226k [00:00<00:00, 1.20MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOkCokJxpxlr",
        "outputId": "958e0d07-99db-4ad2-90f7-8d067dc225dc"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([ 8191, 14129,  2003,  1996,  3871,  2103,  1997,  2634],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.ElectraTokenizer.from_preset(\"electra_base_generator_uncased_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9T-Pymupz5r",
        "outputId": "d8743746-ad80-4846-98de-2e0ff6580726"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_base_generator_uncased_en/1/download/metadata.json...\n",
            "100%|██████████| 140/140 [00:00<00:00, 212kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_base_generator_uncased_en/1/download/tokenizer.json...\n",
            "100%|██████████| 559/559 [00:00<00:00, 869kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_base_generator_uncased_en/1/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 226k/226k [00:00<00:00, 1.20MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcI6DLk4qAGk",
        "outputId": "711f1e38-89ca-4534-913e-2ca071168029"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([ 8191, 14129,  2003,  1996,  3871,  2103,  1997,  2634],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.ElectraTokenizer.from_preset(\"electra_large_generator_uncased_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfZnUPhsqDnk",
        "outputId": "505e9d26-c8fd-4537-b4ae-d484753fb234"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_large_generator_uncased_en/1/download/metadata.json...\n",
            "100%|██████████| 140/140 [00:00<00:00, 158kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_large_generator_uncased_en/1/download/tokenizer.json...\n",
            "100%|██████████| 559/559 [00:00<00:00, 877kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/electra/keras/electra_large_generator_uncased_en/1/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 226k/226k [00:00<00:00, 1.20MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_EZduCxqWm6",
        "outputId": "71498b2e-a004-4b6a-8e2a-bbf4c35a245d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              "array([ 8191, 14129,  2003,  1996,  3871,  2103,  1997,  2634],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.FNetTokenizer.from_preset(\"f_net_base_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6Ptm5-1qZUC",
        "outputId": "ae994aa6-90f1-4cad-e9e0-16a115646902"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/f_net/keras/f_net_base_en/2/download/metadata.json...\n",
            "100%|██████████| 140/140 [00:00<00:00, 193kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/f_net/keras/f_net_base_en/2/download/tokenizer.json...\n",
            "100%|██████████| 399/399 [00:00<00:00, 603kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/f_net/keras/f_net_base_en/2/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 692k/692k [00:00<00:00, 2.36MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktqymF0WqqYc",
        "outputId": "7e602f5a-526d-493a-a1fb-f81836969001"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=\n",
              "array([16135,    34, 11742,    65,    13,  3704,  1558,    39,  2869],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.FNetTokenizer.from_preset(\"f_net_large_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWVxYieqqs-v",
        "outputId": "83abc1ad-1b21-4eb0-ff0c-c135ae8c2ee7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/f_net/keras/f_net_large_en/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 194kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/f_net/keras/f_net_large_en/2/download/tokenizer.json...\n",
            "100%|██████████| 399/399 [00:00<00:00, 459kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/f_net/keras/f_net_large_en/2/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 692k/692k [00:00<00:00, 2.36MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdoTorDJq0ua",
        "outputId": "e066fdb6-3537-4159-8c18-3dcdfbb3354c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=\n",
              "array([16135,    34, 11742,    65,    13,  3704,  1558,    39,  2869],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGVxMg4_q4In",
        "outputId": "6ff839d0-eb32-4718-9431-6303a6568df8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 192kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 592kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 3.09MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.76MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P86gejTcrrt5",
        "outputId": "8402ae24-ae0f-4796-a6e7-c99825d11ecd"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([   33,  1516,   282, 14717,   318,   262, 11376,  1748,   286,\n",
              "        3794], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset('gpt2_medium_en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrhXkZZnsCP4",
        "outputId": "55373d5d-a4ac-4e60-ce91-671124b02ffa"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_medium_en/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 195kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_medium_en/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 538kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_medium_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 3.10MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_medium_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.76MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEq8hq0DsUHZ",
        "outputId": "44b02bb6-5072-430c-ad75-45668e859371"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([   33,  1516,   282, 14717,   318,   262, 11376,  1748,   286,\n",
              "        3794], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_large_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRPlNDgPsWl9",
        "outputId": "9a00bdba-df30-41f0-9239-1b6fdfea0121"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 197kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 678kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 3.11MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_large_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.74MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JYIeIWYsgFq",
        "outputId": "2fc7bef0-aac7-49b9-ed21-79d43cfc9839"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([   33,  1516,   282, 14717,   318,   262, 11376,  1748,   286,\n",
              "        3794], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_extra_large_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1AxapLsjCH",
        "outputId": "16144faf-3b6d-4261-e828-78fb2abef90f"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_extra_large_en/2/download/metadata.json...\n",
            "100%|██████████| 142/142 [00:00<00:00, 171kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_extra_large_en/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 689kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_extra_large_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 2.92MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_extra_large_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.76MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYwcZhT2sq9A",
        "outputId": "6fbeb9f5-0987-4df6-e446-8c46874deb8e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([   33,  1516,   282, 14717,   318,   262, 11376,  1748,   286,\n",
              "        3794], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en_cnn_dailymail\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FoIopmmsuBK",
        "outputId": "adca003d-785a-43c6-bd74-0ff70b7e787b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en_cnn_dailymail/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 185kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en_cnn_dailymail/2/download/tokenizer.json...\n",
            "100%|██████████| 448/448 [00:00<00:00, 614kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en_cnn_dailymail/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 3.11MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en_cnn_dailymail/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.76MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BblNhhups2w5",
        "outputId": "166af582-ee91-458b-de22-ecf22517b408"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([   33,  1516,   282, 14717,   318,   262, 11376,  1748,   286,\n",
              "        3794], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.MistralTokenizer.from_preset(\"mistral_7b_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ_jNcMQs5W4",
        "outputId": "2efe20ae-276f-4264-abad-09450a9e0a3d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/mistral/keras/mistral_7b_en/6/download/metadata.json...\n",
            "100%|██████████| 142/142 [00:00<00:00, 169kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/mistral/keras/mistral_7b_en/6/download/tokenizer.json...\n",
            "100%|██████████| 407/407 [00:00<00:00, 449kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/mistral/keras/mistral_7b_en/6/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 482k/482k [00:00<00:00, 1.84MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj85CRxjtG8P",
        "outputId": "3bbf749e-59a8-4b70-c30b-981045975fe7"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=\n",
              "array([22047,   282, 19099,   349,   272,  8759,  2990,   302,  5558],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.MistralTokenizer.from_preset(\"mistral_0.2_instruct_7b_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWMvcnuRtWJ5",
        "outputId": "30de6fdd-46c3-41c3-c829-a98514a148b2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/mistral/keras/mistral_0.2_instruct_7b_en/1/download/metadata.json...\n",
            "100%|██████████| 142/142 [00:00<00:00, 199kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/mistral/keras/mistral_0.2_instruct_7b_en/1/download/tokenizer.json...\n",
            "100%|██████████| 407/407 [00:00<00:00, 528kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/mistral/keras/mistral_0.2_instruct_7b_en/1/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 482k/482k [00:00<00:00, 1.85MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ8E9GJAtlLv",
        "outputId": "5b0cc4f5-cc41-4a25-be7e-5e05ccc44558"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int32, numpy=\n",
              "array([22047,   282, 19099,   349,   272,  8759,  2990,   302,  5558],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.OPTTokenizer.from_preset(\"opt_125m_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrVfeB3ltn6L",
        "outputId": "8cd1aad6-4dd2-4017-f233-1f65bb250762"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/opt/keras/opt_125m_en/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 200kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/opt/keras/opt_125m_en/2/download/tokenizer.json...\n",
            "100%|██████████| 443/443 [00:00<00:00, 611kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/opt/keras/opt_125m_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 3.10MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/opt/keras/opt_125m_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.74MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_e9LDrwt3N1",
        "outputId": "ec642f42-00bd-4c77-c31e-b8a55999f51e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([ 387, 3314,  337, 5515,   16,    5, 5671,  343,    9,  666],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.RobertaTokenizer.from_preset(\"roberta_large_en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOCH1ohdt6Ds",
        "outputId": "07a53b6d-8e71-4f67-e1b6-21bda7fcb968"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_large_en/2/download/metadata.json...\n",
            "100%|██████████| 141/141 [00:00<00:00, 194kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_large_en/2/download/tokenizer.json...\n",
            "100%|██████████| 463/463 [00:00<00:00, 672kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_large_en/2/download/assets/tokenizer/vocabulary.json...\n",
            "100%|██████████| 0.99M/0.99M [00:00<00:00, 3.10MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_large_en/2/download/assets/tokenizer/merges.txt...\n",
            "100%|██████████| 446k/446k [00:00<00:00, 1.74MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(string_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy5fB8eyuGhV",
        "outputId": "609358fc-c7c0-4266-ae5a-80d31db70c0e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
              "array([ 387, 3314,  337, 5515,   16,    5, 5671,  343,    9,  666],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E0y2B6oJuJ8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}